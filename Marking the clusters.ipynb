{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intergration of findblots, parameter filtering and DBSCAN to mark clusters on cluster images\n",
    "\n",
    "## Background\n",
    "The main purpose of this tool is to improve the marking the clusters by applying SNR, relative fluorescence intensity (RFL), size filtering thresholds to remove the markings on the fake clusters and a clustering method called Density-Based Spatial Clustering (DBSCAN) to remove the repeat clusters that are initially marked by findblots. This analysis tool is writtern in Python.  \n",
    "\n",
    "The SNR, relative fluorescence intensity (RFL), and size filtering thresholds are all based on percentile removal. Due to the conditions of different images vary, the threshold percentile can vary between images. However, the two parameters for DBSCAN clustering, eps and min_samples, should be very similar (or the same) for different images. The principle of DBSCAN clustering can be found in these couple links: **[document link](https://towardsdatascience.com/dbscan-algorithm-complete-guide-and-application-with-python-scikit-learn-d690cbae4c5d)** and **[youtube link](https://www.youtube.com/watch?v=6jl9KkmgDIw&t=10s)**. Based on the inital evaluation, eps = 3.5 and min_samples = 2 are good for most images. \n",
    "\n",
    "## Workflow\n",
    "The overall workflow is (1) import the python package, (2) run the findblot analysis, (3) analyze the images either using the specific image scripts or the images in a folder scripts. To run the findblot, you can use the findblots GUI and you can find a copy in findblots GUI in this folder (**SequLiteNAS\\SequLite Storage\\Chemistry\\Bioinformatics_KW\\Cluster_density\\**) and once you are in this folder, double click the **ClusterAnalysisTool.exe**. To be consistent with the Engineering team, analyze the images using the default parameters except changing the **SNR to from 1 to 2.5**. Alternatively, you can also run the findblots using the scripts (step 2) in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Import the python package for the analysis \n",
    "\n",
    "If you have not download these packages, you will need to download them in your python environment. You can either do it in anaconda environment page or terminal. Run the following cell to import the python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import package for data analysis \n",
    "import sys, os, imageio, csv, glob, re, random, subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io as skimageio\n",
    "from skimage.color import gray2rgb\n",
    "from statistics import mean\n",
    "from pathlib import Path\n",
    "from plotnine import *\n",
    "from sklearn.cluster import DBSCAN\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Run Findblots analysis\n",
    "\n",
    "You can either run the findblots using the GUI or using the script here. There are two scripts: one for analyze the images in a folder and the other one is to analyze a specific images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2a) Analyze the images in a folder\n",
    "\n",
    "Input the **findblot_path** for where FindBlobs-static.exe file is located and **file_path** for where the images are located. Here are the description of FindBlob Options:\n",
    "\n",
    "-C/--useCorners      \tjoin corner connected blobs: [0]\n",
    "<br>\n",
    "-f/--filter          \tuse Fourier space filtering: [[0, 1]]\n",
    "<br>\n",
    "-G/--tileGeom        \tuse tiles with geometry \"width height\" and interpolation (<1 - piecewise, >=1 - linear): [[50, 0, 0]]\n",
    "<br>\n",
    "-I/--pixInt          \ttype of subpixel interpolation: [0]\n",
    "<br>\n",
    "&emsp;0 - center mass of the blob,\n",
    "<br>\n",
    "&emsp;1 - correction for subtracted bkgnd over 3x3 area\n",
    "<br>\n",
    "&emsp;2 - correction for subtracted bkgnd over 5x5 area\n",
    "<br>\n",
    "&emsp;3 - peak position of Gaussian fit over 3x3 area\n",
    "<br>\n",
    "&emsp;4 - peak position of spline fit over 3x3 area\n",
    "<br>\n",
    "-K/--saveMask        \tsave binary mask: [0]\n",
    "<br>\n",
    "-N/--imageNum        \timage number in a stack: [0]\n",
    "<br>\n",
    "-p/--pixelLimits     \tset blob pixel limits \"min max\": [[-1, 0]]\n",
    "<br>\n",
    "-P/--savePNG         \tsave view in PNG (or TIFF for Windows) file: [1]\n",
    "<br>\n",
    "-Q/--imageQuality    \tsave image QC CSV file with SNR threshold: [2.5]\n",
    "<br>\n",
    "-r/--resolution      \tblob resoltion in pixels: [0]\n",
    "<br>\n",
    "-t/--thresh          \tthreshold divider: [0.75]\n",
    "    \n",
    "You can change the findblot option but changing the input in the following cell. **But make sure to have the quotation for the input like Q = '0' not Q = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the path for data analysis\n",
    "findblot_path = \"C:/Users/kelvin/Documents/Bioinformatics_analysis/\"\n",
    "file_path = \"D:/CG_results/Example5/\"\n",
    "\n",
    "#input parameter for the findblot analysis. Make sure to have the quotation like Q = '0' not Q = 0\n",
    "C = '0'\n",
    "f = '0, 1'\n",
    "G = '50, 50, 1'\n",
    "I = '0'\n",
    "K = '0'\n",
    "N = '0'\n",
    "P = '1'\n",
    "S = '1'\n",
    "Q = '2.5'\n",
    "r = '0'\n",
    "t = '0.75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findblot script - no need to change anything here\n",
    "excutablefile = os.path.join(findblot_path + \"FindBlobs-static.exe\")\n",
    "for filename in os.listdir(file_path):\n",
    "    if \"img\" not in filename and \"tif\" in filename and \"Focused\" not in filename:\n",
    "        full_path = os.path.join(file_path, filename)\n",
    "        \n",
    "        cmd = [excutablefile,\n",
    "               '-C', C,\n",
    "               '-f', f,\n",
    "               '-G', G,\n",
    "               '-I', I,\n",
    "               '-K', K,\n",
    "               '-N', N,\n",
    "               '-P', P,\n",
    "               '-S', S,\n",
    "               '-Q', Q, \n",
    "               '-r', r, \n",
    "               '-t', t, full_path]\n",
    "        subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2a) Analyze a specific image\n",
    "\n",
    "If you choose to analyze a specific image, you can run the scripts in the following two cells. The first cell is to enter the **findblot_path** for where FindBlobs-static.exe file is located and **image_path** for where the image file is located. You can change the findblot option but changing the input in the following cell. **But make sure to have the quotation for the input like Q = '0' not Q = 0**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the path for data analysis\n",
    "findblot_path = \"C:/Users/kelvin/Documents/Bioinformatics_analysis/\"\n",
    "image_path = \"D:/CG_results/Example5/example1.tif\"\n",
    "\n",
    "#input parameter for the findblot analysis. Make sure to have the quotation like Q = '0' not Q = 0\n",
    "C = '0'\n",
    "f = '0, 1'\n",
    "G = '50, 50, 1'\n",
    "I = '0'\n",
    "K = '0'\n",
    "N = '0'\n",
    "P = '1'\n",
    "S = '1'\n",
    "Q = '2.5'\n",
    "r = '0'\n",
    "t = '0.75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['C:/Users/kelvin/Documents/Bioinformatics_analysis/FindBlobs-static.exe', '-C', '0', '-f', '0, 1', '-G', '50, 50, 1', '-I', '0', '-K', '0', '-N', '0', '-P', '1', '-S', '1', '-Q', '2.5', '-r', '0', '-t', '0.75', 'D:/CG_results/Example5/example1.tif'], returncode=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#findblot script - no need to change anything here\n",
    "excutablefile = os.path.join(findblot_path + \"FindBlobs-static.exe\")\n",
    "cmd = [excutablefile,\n",
    "       '-C', C,\n",
    "       '-f', f,\n",
    "       '-G', G,\n",
    "       '-I', I,\n",
    "       '-K', K,\n",
    "       '-N', N,\n",
    "       '-P', P,\n",
    "       '-S', S,\n",
    "       '-Q', Q, \n",
    "       '-r', r, \n",
    "       '-t', t, image_path]\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Removal of repeat clusters and clusters with low QC values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3a) Analyze the images by folder \n",
    "\n",
    "If you choose to analyze images by folder, you should begin with having only the raw or greyscale composite image files (.tif) in the input folder (file_path). After runing the findblots, you can proceed with the analysis in this section.\n",
    "\n",
    "The following two cells is to analyze images in a folder. The first cell is to input parameters and specify folder paths. There are six parameters: \n",
    "1. **size_thresold** = the clusters have lower than the specified percentile of size will be removed \n",
    "2. **size_upper_thresold** = the clusters have higher than the specified percentile of size will be removed \n",
    "3. **SNR_thresold** = the clusters have lower than the specified percentile of SNR will be removed\n",
    "4. **RFL_thresold** = the clusters have lower than the specified percentile of RFL will be removed \n",
    "5. **eps** = the maximum distance between two samples for one to be considered as in the neighborhood of the other\n",
    "6. **min_samples** = the number of samples (or total weight) in a neighborhood for a point to be considered as a core point (should always be 2 in our case)\n",
    "\n",
    "There are also two folder paths in the first cell:\n",
    "1. **file_path** = it is the input folder. It **must** contain two types of file:  \n",
    "    1. composite greyscale or raw image. The four composite image file must be converted to greyscale. \n",
    "    2. findblot csv files (000000-loc.csv). This is the csv files generated from findblot tools\n",
    "2. **output_folder_path** = it is the folder path that you want your results to be stored. There are three types of files:\n",
    "    1. image files with the new cluster marking after filtering by different thresolds and DBSCAN. \n",
    "    2. CSV files with the new cluster marking after filtering by different thresolds and DBSCAN. \n",
    "    3. Total number of clusters in each image files\n",
    "    \n",
    "After finish entering the input in the first cell, run both cells **sequentially**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first cell for the \"analyze the images in a folder\" \n",
    "size_thresold = 5\n",
    "size_upper_thresold = 98\n",
    "SNR_thresold = 0\n",
    "RFL_thresold = 5\n",
    "eps = 3.5\n",
    "min_samples = 2\n",
    "\n",
    "file_path = \"D:/CG_results/Example5/\"\n",
    "output_folder_path = \"D:/CG_results/Example5/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second cell for the \"analyze the images in a folder\", do not modify the codes here unless you are \n",
    "# confident with the modifications\n",
    "\n",
    "# function to mark the clusters\n",
    "bar_thickness = 0\n",
    "half_bar_length = 1\n",
    "def mark_image_location_rgb(X, Y):\n",
    "  for i in range(max(0, Y-half_bar_length), min(Y+half_bar_length+1,image_rgb.shape[0])):\n",
    "    for j in range(max(0, X-half_bar_length), min(X+half_bar_length+1,image_rgb.shape[1])):\n",
    "      if abs(i-Y) <= bar_thickness or abs(j-X) <= bar_thickness:\n",
    "        image_rgb[i,j,0]=0\n",
    "        image_rgb[i,j,1]=0x7FFF\n",
    "        image_rgb[i,j,2]=0x7FFF\n",
    "\n",
    "def make_folder(save_folder):\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "        \n",
    "cvsfile = [file_path + x for x in os.listdir(path = file_path) if \"000000-loc.csv\" in x] \n",
    "all_image = [file_path + x for x in os.listdir(path = file_path) if \".tif\" in x] \n",
    "imagefile = [x for x in all_image if '000000-img.tif' not in x]\n",
    "\n",
    "key_list = []\n",
    "item_list = []\n",
    "for i in range(0, len(cvsfile)):\n",
    "    db = pd.read_csv(cvsfile[i],\n",
    "                            sep = \",\")\n",
    "    db['size'] = db['GaussSigmaY'] * db['GaussSigmaX']\n",
    "\n",
    "    db1 = db[db['size'] > 0]\n",
    "    df1 = db1[(db1['size'] > np.percentile(db1['size'], size_thresold)) & \n",
    "              (db1['size'] < np.percentile(db1['size'], size_upper_thresold)) &\n",
    "              (db1['SNR'] > np.percentile(db1['SNR'], SNR_thresold)) &\n",
    "              (db1['Signal'] > np.percentile(db1['Signal'], RFL_thresold))]\n",
    "\n",
    "    dbb = DBSCAN(eps= eps, min_samples = min_samples).fit(df1[['X', 'Y']])\n",
    "    cluster_labels = dbb.labels_\n",
    "\n",
    "    df1['group_ID'] = cluster_labels\n",
    "    df2 = df1\n",
    "    df3 = df2[df2.group_ID != -1].sort_values(by=['group_ID'])\\\n",
    "            .groupby('group_ID')\\\n",
    "            .mean().reset_index()\\\n",
    "            .append(df2[df2.group_ID == -1])\n",
    "    \n",
    "    make_folder(output_folder_path)\n",
    "    csvpath = output_folder_path + \"temp.csv\"\n",
    "    df3.to_csv(csvpath, sep=',', index=False)\n",
    "    \n",
    "    imagefile_in = imagefile[i]\n",
    "    image_gray = skimageio.imread(imagefile_in, True)\n",
    "    image_rgb = gray2rgb(image_gray)\n",
    "    with open(csvpath, mode='r', encoding=\"utf-8-sig\") as csv_file:\n",
    "      csv_reader = csv.DictReader(csv_file)\n",
    "      for row in csv_reader:\n",
    "        mark_image_location_rgb(int(float(row['X'])), int(float(row['Y'])))\n",
    "    path_basename = os.path.basename(imagefile_in)\n",
    "    base_name = os.path.splitext(path_basename)[0]\n",
    "    imagefile_out = output_folder_path + \"/\" + base_name + \\\n",
    "        \"_marked_\" + \\\n",
    "        \"size_\" + str(size_thresold) + \\\n",
    "         \"_SNR_\" + str(SNR_thresold) + \\\n",
    "         \"_RFL_\" + str(RFL_thresold)  \n",
    "    skimageio.imsave(imagefile_out + \"_filter_dbscan.tif\", image_rgb)\n",
    "    df3.to_csv(imagefile_out + \"_filter-loc.csv\", sep=',', index=False)\n",
    "    \n",
    "    key_list.append(path_basename.replace('.tif', ''))\n",
    "    item_list.append(df3.shape[0])\n",
    "\n",
    "cluster_num_dict = dict(zip(key_list, item_list))\n",
    "df4 = pd.DataFrame(list(cluster_num_dict.items()),columns = ['file_name','number_of_cluster']) \n",
    "df4.to_csv(output_folder_path + \\\n",
    "           \"size_\" + str(size_thresold) + \\\n",
    "           \"_SNR_\" + str(SNR_thresold) + \\\n",
    "           \"_RFL_\" + str(RFL_thresold)  + \"_number_clusters.csv\", sep=',', index=False)\n",
    "os.remove(csvpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3b) Analyze a specific image\n",
    "\n",
    "**The following two cells is to analyze a specific image. The first cell is to input parameter and specify folder path. There are also six parameters:** \n",
    "1. **size_thresold** = the clusters have lower than the specified percentile of size will be removed \n",
    "2. **size_upper_thresold** = the clusters have higher than the specified percentile of size will be removed \n",
    "3. **SNR_thresold** = the clusters have lower than the specified percentile of SNR will be removed\n",
    "4. **RFL_thresold** = the clusters have lower than the specified percentile of RFL will be removed \n",
    "5. **eps** = the maximum distance between two samples for one to be considered as in the neighborhood of the other\n",
    "6. **min_samples** = the number of samples (or total weight) in a neighborhood for a point to be considered as a core point (should always be 2 in our case)\n",
    "\n",
    "**There are also three folder paths in the first cell:**\n",
    "1. **image_file_path** = it is the image file folder. It contain either the composite greyscale or raw image. The four composite image file must be converted to greyscale. \n",
    "2. **csv_file_path** = findblot csv files (000000-loc.csv). This is the csv files generated from findblot tools\n",
    "3. **output_folder_path** = it is the folder path that you want your results to be stored.\n",
    "    \n",
    "After finish entering the input in the first cell, run both cells **sequentially**. **The number of clusters will be printed out after finish running the script.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first cell for the \"analyze the images in a folder\" \n",
    "size_thresold = 0\n",
    "size_upper_thresold = 98\n",
    "SNR_thresold = 0\n",
    "RFL_thresold = 0\n",
    "eps = 3.5\n",
    "min_samples = 2\n",
    "\n",
    "image_file_path = \"C:Downloads/CRT68y_Inc_Inc1_composite_b00.00mm_305.26um_0.200s.tif\"\n",
    "csv_file_path = \"C:Downloads/CRT68y_Inc_Inc1_composite_b00.00mm_305.26um_0.200s_000000-loc.csv\"\n",
    "output_folder_path = \"C:Downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35717 of clusters identified in this image\n"
     ]
    }
   ],
   "source": [
    "# second cell for the \"analyze a specific image\", do not modify the codes here unless you are \n",
    "# confident with the modifications\n",
    "\n",
    "# function to mark the clusters\n",
    "bar_thickness = 0\n",
    "half_bar_length = 1\n",
    "def mark_image_location_rgb(X, Y):\n",
    "  for i in range(max(0, Y-half_bar_length), min(Y+half_bar_length+1,image_rgb.shape[0])):\n",
    "    for j in range(max(0, X-half_bar_length), min(X+half_bar_length+1,image_rgb.shape[1])):\n",
    "      if abs(i-Y) <= bar_thickness or abs(j-X) <= bar_thickness:\n",
    "        image_rgb[i,j,0]=0\n",
    "        image_rgb[i,j,1]=0x7FFF\n",
    "        image_rgb[i,j,2]=0x7FFF\n",
    "        \n",
    "db = pd.read_csv(csv_file_path, sep = \",\")\n",
    "db['size'] = db['GaussSigmaY'] * db['GaussSigmaX']\n",
    "\n",
    "db1 = db[db['size'] > 0]\n",
    "df1 = db1[(db1['size'] > np.percentile(db1['size'], size_thresold)) & \n",
    "          (db1['size'] < np.percentile(db1['size'], size_upper_thresold)) &\n",
    "          (db1['SNR'] > np.percentile(db1['SNR'], SNR_thresold)) &\n",
    "          (db1['Signal'] > np.percentile(db1['Signal'], RFL_thresold))]\n",
    "\n",
    "dbb = DBSCAN(eps= eps, min_samples = min_samples).fit(df1[['X', 'Y']])\n",
    "cluster_labels = dbb.labels_\n",
    "\n",
    "df1['group_ID'] = cluster_labels\n",
    "df2 = df1\n",
    "df3 = df2[df2.group_ID != -1].sort_values(by=['group_ID'])\\\n",
    "        .groupby('group_ID')\\\n",
    "        .mean().reset_index()\\\n",
    "        .append(df2[df2.group_ID == -1])\n",
    "\n",
    "make_folder(output_folder_path)\n",
    "csvpath = output_folder_path + \"temp.csv\"\n",
    "df3.to_csv(csvpath, sep=',', index=False)\n",
    "\n",
    "imagefile_in = image_file_path\n",
    "image_gray = skimageio.imread(imagefile_in, True)\n",
    "image_rgb = gray2rgb(image_gray)\n",
    "with open(csvpath, mode='r', encoding=\"utf-8-sig\") as csv_file:\n",
    "  csv_reader = csv.DictReader(csv_file)\n",
    "  for row in csv_reader:\n",
    "    mark_image_location_rgb(int(float(row['X'])), int(float(row['Y'])))\n",
    "path_basename = os.path.basename(imagefile_in)\n",
    "base_name = os.path.splitext(path_basename)[0]\n",
    "imagefile_out = output_folder_path + \"/\" + base_name + \\\n",
    "    \"_marked_\" + \\\n",
    "    \"size_\" + str(size_thresold) + \\\n",
    "     \"_SNR_\" + str(SNR_thresold) + \\\n",
    "     \"_RFL_\" + str(RFL_thresold) \n",
    "skimageio.imsave(imagefile_out + \"_filter_dbscan.tif\", image_rgb)\n",
    "df3.to_csv(imagefile_out + \"_filter-loc.csv\", sep=',', index=False)    \n",
    "os.remove(csvpath)\n",
    "\n",
    "print(\"There are \" + str(df3.shape[0]) + \" of clusters identified in this image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
